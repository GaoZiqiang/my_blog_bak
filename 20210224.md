## 1 梯度下降算法
如[上篇博文](https://blog.csdn.net/qq_33429968/article/details/103896240)所言，我们的最终目的是将代价函数最小化，以求得最优目标函数。在这里我们求解最小代价函数所使用的算法是梯度下降算法。
首先贴上梯度下降算法的数学表达式。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200227171315325.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNDI5OTY4,size_16,color_FFFFFF,t_70)
## 2 算法思想
下面先从一个我们熟悉的场景解释一下该算法的算法思想。
### 2.1 场景假设
梯度下降法的基本思想可以类比为一个**下山**的过程。（此处参考[https://blog.csdn.net/qq_41800366/article/details/86583789](https://blog.csdn.net/qq_41800366/article/details/86583789)）
假设这样一个场景：一个人被困在山上，需要从山上下来(找到山的**最低点**，也就是山谷)。但此时山上的浓雾很大，导致可视度很低；因此，下山的路径就无法确定，必须利用自己周围的信息一小步一小步地找到下山的路。这个时候，便可利用梯度下降算法来帮助自己下山。*怎么做呢，首先以他当前的所处的位置为基准，寻找这个位置最陡峭的地方，然后朝着下降方向走一步，然后又继续以当前位置为基准，再找最陡峭的地方，再走直到最后到达最低*处；同理上山也是如此，只是这时候就变成梯度上升算法了。
![图2.1](https://img-blog.csdnimg.cn/20200227164015803.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNDI5OTY4,size_16,color_FFFFFF,t_70)
上述下山过程从**二维**角度理解，就是这样的：![图2.1-2](https://img-blog.csdnimg.cn/20200227164210893.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNDI5OTY4,size_16,color_FFFFFF,t_70)
### 2.2 算法本质
通过上面的情景假设，我们可以这样理解**梯度算法的本质**：
梯度算法的本质是一个不断迭代的过程，它通过逐步求取每一个小过程的最优解，步步为营，最终得到整个函数的最优解。
## 3 从数学角度解释算法原理
### 3.1 公式的运行过程
从初始θ_0、θ_1出发，分别通过下面一组公式对θ_0、θ_1进行更新。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200227170925184.png)
**梯度算法的本质是一个不断迭代的过程，两个参数在更新的过程中偏导数不断减小，当到达局部最低点时，偏导数减小到0，那么θ_0、θ_1也就不变了，此时得到的两参数θ_0、θ_1即为最优解，从而得到最优代价函数**。（如下图所示）
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200227170441513.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNDI5OTY4,size_16,color_FFFFFF,t_70)
**Notes**:有一种易错计算方式如下。
这种方式计算出的θ_0、θ_1两个参数就是去了同步性，因此是不对的。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200227165029930.png)
### 3.2 参数解析
下面的参数解析以仅含有一个参数的函数为例子进行。
**1 α的实际意义**
α的实际意义为**学习率**（learning rate），可以理解为下山的步伐大小，也即从初始点趋向于局部最低（小）点的幅度大小。
当α适中时，如下图所示，从初始点可以逐步到达局部最低点。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200227163815393.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNDI5OTY4,size_16,color_FFFFFF,t_70)
而当α的过大时，如下图所示，其趋向过程中由于幅度过大，很容易越过最低点，从而使函数无法收敛甚至发散，从而找不到局部最低点。
![在这里插入图片描述](https://img-blog.csdnimg.cn/2020022716364510.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNDI5OTY4,size_16,color_FFFFFF,t_70)
**2 梯度的物理意义**
梯度的本质是一个**向量**，它的物理意义为指示某个**方向**（两个点之间），例如在三维坐标下一个梯度需要有3个方向的参数指示一个具体的方向。
在本算法中，梯度是不断减小的，当梯度减小为0时，参数也得到了最小值。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200227165616363.png)
## 4 参考资料
1 [https://blog.csdn.net/qq_41800366/article/details/86583789](https://blog.csdn.net/qq_41800366/article/details/86583789)
2 [https://study.163.com/course/courseLearn.htm?courseId=1004570029#/learn/video?lessonId=1049105129&courseId=1004570029](https://study.163.com/course/courseLearn.htm?courseId=1004570029#/learn/video?lessonId=1049105129&courseId=1004570029)
